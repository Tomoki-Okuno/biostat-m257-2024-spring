{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "Biostat/Biomath M257 Homework 3\n",
    "\n",
    "Due May 3 @ 11:59PM\n",
    "\n",
    "Tomoki Okuno and 805851067"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "System information (for reproducibility):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Julia Version 1.10.0\n",
      "Commit 3120989f39b (2023-12-25 18:01 UTC)\n",
      "Build Info:\n",
      "  Official https://julialang.org/ release\n",
      "Platform Info:\n",
      "  OS: macOS (arm64-apple-darwin22.4.0)\n",
      "  CPU: 8 × Apple M1\n",
      "  WORD_SIZE: 64\n",
      "  LIBM: libopenlibm\n",
      "  LLVM: libLLVM-15.0.7 (ORCJIT, apple-m1)\n",
      "  Threads: 2 on 4 virtual cores\n"
     ]
    }
   ],
   "source": [
    "versioninfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `~/Documents/07_UCLA/Class/257/02_Homework/hw3`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1mStatus\u001b[22m\u001b[39m `~/Documents/07_UCLA/Class/257/02_Homework/hw3/Project.toml`\n",
      "  \u001b[90m[6e4b80f9] \u001b[39mBenchmarkTools v1.5.0\n",
      "  \u001b[90m[31c24e10] \u001b[39mDistributions v0.25.108\n",
      "  \u001b[90m[37e2e46d] \u001b[39mLinearAlgebra\n",
      "  \u001b[90m[9a3f8284] \u001b[39mRandom\n"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "\n",
    "Pkg.activate(pwd())\n",
    "Pkg.instantiate()\n",
    "Pkg.status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "using LinearAlgebra, Random\n",
    "using BenchmarkTools, Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider a linear mixed effects model\n",
    "$$\n",
    "    \\mathbf{Y}_i = \\mathbf{X}_i \\boldsymbol{\\beta} + \\mathbf{Z}_i \\boldsymbol{\\gamma} + \\boldsymbol{\\epsilon}_i, \\quad i=1,\\ldots,n,\n",
    "$$\n",
    "where   \n",
    "- $\\mathbf{Y}_i \\in \\mathbb{R}^{n_i}$ is the response vector of $i$-th individual,  \n",
    "- $\\mathbf{X}_i \\in \\mathbb{R}^{n_i \\times p}$ is the fixed effect predictor matrix of $i$-th individual,  \n",
    "- $\\mathbf{Z}_i \\in \\mathbb{R}^{n_i \\times q}$ is the random effect predictor matrix of $i$-th individual,  \n",
    "- $\\boldsymbol{\\epsilon}_i \\in \\mathbb{R}^{n_i}$ are multivariate normal $N(\\mathbf{0}_{n_i},\\sigma^2 \\mathbf{I}_{n_i})$,  \n",
    "- $\\boldsymbol{\\beta} \\in \\mathbb{R}^p$ are fixed effects, and  \n",
    "- $\\boldsymbol{\\gamma} \\in \\mathbb{R}^q$ are random effects assumed to be $N(\\mathbf{0}_q, \\boldsymbol{\\Sigma}_{q \\times q}$) independent of $\\boldsymbol{\\epsilon}_i$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1 Formula (10 pts)\n",
    "\n",
    "Write down the log-likelihood of the $i$-th datum $(\\mathbf{y}_i, \\mathbf{X}_i, \\mathbf{Z}_i)$ given parameters $(\\boldsymbol{\\beta}, \\boldsymbol{\\Sigma}, \\sigma^2)$.\n",
    "\n",
    "**Solution**\n",
    "\n",
    "Since $\\boldsymbol{\\gamma}$ is independent of $\\boldsymbol{\\epsilon}_i$, we have $\\mathbf{y}_i \\sim N(\\mathbf{X}_i \\boldsymbol{\\beta}, \\mathbf{\\Omega}_i)$, where $\\mathbf{\\Omega}_i = \\mathbf{Z}_i \\boldsymbol{\\Sigma} \\mathbf{Z}_i' + \\sigma^2 \\mathbf{I}_{n_i}$. Hence, the likelihood $L(\\boldsymbol{\\beta}, \\boldsymbol{\\Sigma}, \\sigma^2)$ is written as\n",
    "$$\n",
    "    L(\\boldsymbol{\\beta}, \\boldsymbol{\\Sigma}, \\sigma^2) = \n",
    "    (2\\pi)^{-n_i/2}\\vert\\mathbf{\\Omega}_i\\vert^{-1/2}\n",
    "    \\exp\\left[-\\frac {(\\mathbf{y}_i - \\mathbf{X}_i \\boldsymbol{\\beta})^T\\mathbf{\\Omega}_i^{-1}(\\mathbf{y}_i - \\mathbf{X}_i \\boldsymbol{\\beta})} 2\\right],\n",
    "$$\n",
    "and thus the log-likelihood $\\ell(\\boldsymbol{\\beta}, \\boldsymbol{\\Sigma}, \\sigma^2)$ is given by\n",
    "$$\n",
    "\\begin{align}\n",
    "    \\ell(\\boldsymbol{\\beta}, \\boldsymbol{\\Sigma}, \\sigma^2) \n",
    "    &=\n",
    "    - \\frac{n_i} 2 \\ln(2\\pi)\n",
    "    - \\frac 1 2 \\ln\\vert\\mathbf{\\Omega}_i\\vert\n",
    "    - \\frac 1 2 (\\mathbf{y}_i - \\mathbf{X}_i \\boldsymbol{\\beta})^T\\mathbf{\\Omega}_i^{-1}(\\mathbf{y}_i - \\mathbf{X}_i \\boldsymbol{\\beta}).\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2 Start-up code\n",
    "\n",
    "Use the following template to define a type `LmmObs` that holds an LMM datum $(\\mathbf{y}_i, \\mathbf{X}_i, \\mathbf{Z}_i)$. \n",
    "\n",
    "**Solution**\n",
    "\n",
    "I added `xty`, `zty`, and `yty` to the template for efficient computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LmmObs"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define a type that holds LMM datum\n",
    "struct LmmObs{T <: AbstractFloat}\n",
    "    # data\n",
    "    y :: Vector{T}\n",
    "    X :: Matrix{T}\n",
    "    Z :: Matrix{T}\n",
    "    # working arrays\n",
    "    # whatever intermediate vectors/arrays you may want to pre-allocate\n",
    "    storage_p  :: Vector{T}\n",
    "    storage_q  :: Vector{T}\n",
    "    xtx        :: Matrix{T}\n",
    "    ztx        :: Matrix{T}\n",
    "    ztz        :: Matrix{T}\n",
    "    storage_qq :: Matrix{T}\n",
    "    xty        :: Vector{T} # added\n",
    "    zty        :: Vector{T} # added\n",
    "    yty        :: T         # added\n",
    "end\n",
    "\n",
    "# constructor\n",
    "function LmmObs(\n",
    "    y :: Vector{T}, \n",
    "    X :: Matrix{T}, \n",
    "    Z :: Matrix{T}\n",
    "    ) where T <: AbstractFloat\n",
    "    storage_p  = Vector{T}(undef, size(X, 2))\n",
    "    storage_q  = Vector{T}(undef, size(Z, 2))\n",
    "    xtx        = transpose(X) * X\n",
    "    ztx        = transpose(Z) * X\n",
    "    ztz        = transpose(Z) * Z\n",
    "    storage_qq = similar(ztz)\n",
    "    xty        = transpose(X) * y # added\n",
    "    zty        = transpose(Z) * y # added\n",
    "    yty        = dot(y, y) # added\n",
    "    LmmObs(y, X, Z, storage_p, storage_q, xtx, ztx, ztz, storage_qq, xty, zty, yty)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function, with interface   \n",
    "```julia\n",
    "logl!(obs, β, L, σ²)\n",
    "```\n",
    "that evaluates the log-likelihood of the $i$-th datum. Here `L` is the lower triangular Cholesky factor from the Cholesky decomposition `Σ=LL'`. Make your code efficient in the $n_i \\gg q$ case. Think the intensive longitudinal measurement setting.\n",
    "\n",
    "**Solution**\n",
    "\n",
    "We need to consider efficient computation of $\\ell(\\boldsymbol{\\beta}, \\boldsymbol{\\Sigma}, \\sigma^2)$.\n",
    "\n",
    "Using the determinant property used in hw1 Q5.4, we have\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\vert\\mathbf{\\Omega}_i\\vert\n",
    "&= \\vert\\sigma^2 \\mathbf{I}_{n_i} + \\mathbf{Z}_i\\boldsymbol{\\Sigma}\\mathbf{Z}_i'\\vert\\\\\n",
    "&= \\sigma^{2n_i}\\vert \\mathbf{I}_{n_i} + \\sigma^{-2}\\mathbf{Z}_i\\mathbf{L}\\mathbf{L}'\\mathbf{Z}_i'\\vert\\\\\n",
    "&= \\sigma^{2n_i}\\vert \\mathbf{I}_{q} + \\sigma^{-2}\\mathbf{L}'\\mathbf{Z}_i'\\mathbf{Z}_i\\mathbf{L}\\vert\n",
    "\\end{align*}\n",
    "$$\n",
    "Hence, taking the log gives\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\ln\\vert\\mathbf{\\Omega}_i\\vert = n_i\\ln\\sigma^2 + \\ln\\vert \\mathbf{I}_{q} + \\sigma^{-2}\\mathbf{L}'\\mathbf{Z}_i'\\mathbf{Z}_i\\mathbf{L}\\vert.\n",
    "\\end{align*}\n",
    "$$\n",
    "Using the Woodbury formula shown in hw1 Q5.3, we have\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\mathbf{\\Omega}_i^{-1}\n",
    "&= (\\sigma^2 \\mathbf{I}_{n_i} + \\mathbf{Z}_i\\boldsymbol{\\Sigma}\\mathbf{Z}_i')^{-1}\\\\\n",
    "&= (\\sigma^2 \\mathbf{I}_{n_i} + \\mathbf{Z}_i\\mathbf{L}\\mathbf{L}'\\mathbf{Z}_i')^{-1}\\\\\n",
    "&= \\sigma^{-2} \\mathbf I_{q} - \\sigma^{-4}\\mathbf{Z}_i\\mathbf{L}(\\mathbf{I}_q + \\sigma^{-2}\\mathbf{L}'\\mathbf{Z}_i'\\mathbf{Z}_i\\mathbf{L})^{-1}\\mathbf{L}'\\mathbf{Z}_i'.\n",
    "\\end{align*}\n",
    "$$\n",
    "Then, the third term of the log-likelihood (without the coefficient) can be expanded as follows:\n",
    "$$\n",
    "\\begin{align*}\n",
    "(\\mathbf{y}_i - \\mathbf{X}_i \\boldsymbol{\\beta})'\\mathbf{\\Omega}_i^{-1}(\\mathbf{y}_i - \\mathbf{X}_i \\boldsymbol{\\beta})\n",
    "= \\sigma^{-2}\\|\\mathbf{y}_i - \\mathbf{X}_i \\boldsymbol{\\beta}\\|_2^2\n",
    "- \\sigma^{-4}(\\mathbf{y}_i\n",
    "- \\mathbf{X}_i \\boldsymbol{\\beta})'\\mathbf{Z}_i\\mathbf{L}\n",
    "(\\mathbf{I}_q + \\sigma^{-2}\\mathbf{L}'\\mathbf{Z}_i'\\mathbf{Z}_i\\mathbf{L})^{-1}\n",
    "\\mathbf{L}'\\mathbf{Z}_i'(\\mathbf{y}_i - \\mathbf{X}_i \\boldsymbol{\\beta}),\n",
    "\\end{align*}\n",
    "$$\n",
    "where $\\mathbf{L}'\\mathbf{Z}_i'(\\mathbf{y}_i - \\mathbf{X}_i \\boldsymbol{\\beta})\\in \\mathbb R^q$, which can be stored in `storage_q`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, by another Cholesky decomposition $\\mathbf{I}_q + \\sigma^{-2}\\mathbf{L}'\\mathbf{Z}_i'\\mathbf{Z}_i\\mathbf{L} = \\mathbf{M} \\mathbf{M}'$, the log-likelihood $(1)$ can change to\n",
    "$$\n",
    "\\begin{align*}\n",
    "    \\ell(\\boldsymbol{\\beta}, \\boldsymbol{\\Sigma}, \\sigma^2) \n",
    "    &= - \\frac{n_i} 2 \\ln(2\\pi)\n",
    "    - \\frac 1 2\\left(n_i \\ln\\sigma^2 + \\ln\\vert\\mathbf{M}\\mathbf{M}'\\vert\\right)\\\\\n",
    "    &\\quad - \\frac 1 2 \\left[\\frac{\\|\\mathbf{y}_i - \\mathbf{X}_i \\boldsymbol{\\beta}\\|_2^2}{\\sigma^2}\n",
    "    - \\frac{(\\mathbf{y}_i - \\mathbf{X}_i \\boldsymbol{\\beta})'\\mathbf{Z}_i\\mathbf{L}\n",
    "    (\\mathbf{M}\\mathbf{M}')^{-1}\n",
    "    \\mathbf{L}'\\mathbf{Z}_i'(\\mathbf{y}_i - \\mathbf{X}_i \\boldsymbol{\\beta})}{\\sigma^4}\\right]\\\\\n",
    "    &= - \\frac{n_i} 2 \\ln(2\\pi\\sigma^2)\n",
    "    - \\ln\\vert\\mathbf{M}\\vert\\\\\n",
    "    &\\quad - \\frac 1 2\\frac{\\|\\mathbf{y}_i - \\mathbf{X}_i \\boldsymbol{\\beta}\\|_2^2}{\\sigma^2}\n",
    "    + \\frac 1 2 \\frac{\\|\\mathbf{M}^{-1}\n",
    "    (\\mathbf{L}'\\mathbf{Z}_i'\\mathbf{y}_i - \\mathbf{L}'\\mathbf{Z}_i'\\mathbf{X}_i \\boldsymbol{\\beta})\\|_2^2}{\\sigma^4}.\n",
    "\\end{align*}\n",
    "$$\n",
    "In addition, the following expansion of the numarator in the 3rd term reduces more time and memory:\n",
    "$$\n",
    "\\|\\mathbf{y}_i - \\mathbf{X}_i \\boldsymbol{\\beta}\\|_2^2\n",
    "= \\|\\mathbf{y}_i\\|_2^2 + \\boldsymbol{\\beta}'(\\mathbf{X}_i'\\mathbf{X}_i\\boldsymbol{\\beta} - 2\\mathbf{X}_i'\\mathbf{y}_i),\n",
    "$$\n",
    "where $\\mathbf{X}_i'\\mathbf{X}_i\\boldsymbol{\\beta} - 2\\mathbf{X}_i'\\mathbf{y}_i\\in\\mathbb R^p$, which can be stored in `storage_p`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "logl! (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function logl!(\n",
    "    obs :: LmmObs{T},\n",
    "    β   :: Vector{T},\n",
    "    L   :: Matrix{T}, # lower triangular Cholesky factor\n",
    "    σ²  :: T\n",
    "    ) where T <: AbstractFloat\n",
    "    n, p, q = size(obs.X, 1), size(obs.X, 2), size(obs.Z, 2)\n",
    "    \n",
    "    ## 1st term = -(n/2) log(2πσ²) ----------------------------------------- ##\n",
    "    LogLik = -(n//2) * log(2π * σ²)\n",
    "\n",
    "    ## 2nd term = -logdet(M), where M = L'Z'ZL / σ² + I -------------------- ##\n",
    "    mul!(obs.storage_qq, transpose(L), obs.ztz) # L'Z'Z\n",
    "    BLAS.trmm!('R', 'L', 'N', 'N', 1 / σ², L, obs.storage_qq) # (L'Z'Z)L / σ²\n",
    "\n",
    "    @simd for j in 1:q\n",
    "        obs.storage_qq[j, j] += 1.0 # L'Z'ZL / σ² + I\n",
    "    end\n",
    "\n",
    "    LAPACK.potrf!('L', obs.storage_qq) # M = cholesky!(Symmetric(obs.storage_qq, :L))\n",
    "    LogLik -= logdet(LowerTriangular(obs.storage_qq)) # logdet(M)\n",
    "    # LogLik -= sum(log.(diag(obs.storage_qq))) # requires 2 allocations\n",
    "\n",
    "    ## 3rd term = -1/2 (||y||^2 + β'(X'Xβ - 2X'y)) / σ² -------------------- ##\n",
    "    obs.storage_p .= obs.xty # X'y\n",
    "    BLAS.symv!('U', 1.0, obs.xtx, β, -2.0, obs.storage_p) # X'Xβ - 2X'y\n",
    "    LogLik -= (1//2) * (obs.yty + dot(β, obs.storage_p)) / σ²\n",
    "\n",
    "    ## 4th term = 1/2 ||M⁻¹(L'Z'y - L'Z'Xβ)||² / (σ²)² --------------------- ##\n",
    "    obs.storage_q .= obs.zty # Z'y\n",
    "    BLAS.gemv!('N', -1.0, obs.ztx, β, 1.0, obs.storage_q) # Z'y - Z'Xβ\n",
    "    BLAS.trmv!('L', 'T', 'N', L, obs.storage_q) # L'Z'y - L'Z'Xβ\n",
    "    BLAS.trsv!('L', 'N', 'N', obs.storage_qq, obs.storage_q) # M⁻¹(L'Z'y - L'Z'Xβ\n",
    "    LogLik += (1//2) * dot(obs.storage_q, obs.storage_q) / σ²^2\n",
    " \n",
    "    return LogLik \n",
    "    # return -0.5n * log(2π * σ²) - logdet(LowerTriangular(obs.storage_qq)) - \n",
    "    # 0.5 * (obs.yty + dot(β, obs.storage_p)) / σ² + \n",
    "    # 0.5 * dot(obs.storage_q, obs.storage_q) / σ²^2\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that there was little differnece in running time between calculating each term of the log likelihood as above and combining them as commented out at the end.\n",
    "\n",
    "**Hint**: This function shouldn't be very long. Mine, obeying 92-character rule, is 30 lines. If you find yourself writing very long code, you're on the wrong track. Think about algorithm (flop count) first then use BLAS functions to reduce memory allocations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3 Correctness (15 pts)\n",
    "\n",
    "Compare your result (both accuracy and timing) to the [Distributions.jl](https://juliastats.org/Distributions.jl/stable/multivariate/#Distributions.AbstractMvNormal) package using following data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LmmObs{Float64}([-1.450910909560209, 1.5185224894450862, 5.265021705624027, 4.485272594164557, 0.694969966642933, 1.7723256696372405, 1.1065838446466518, 3.729166811829607, 4.288899999400642, 2.8241842645202406  …  4.058027151891634, 1.0909724390970443, 0.026692243086209766, -0.8927757653299448, 6.94725248926293, 3.5193020855673436, 4.914007299083773, 2.1610206566690797, 1.857389542694909, 6.513818951020866], [1.0 0.6790633442371218 … 0.5400611947971554 -0.632040682052606; 1.0 1.2456776800889142 … -0.4818455756130373 0.6467830314674976; … ; 1.0 0.0733124748775436 … 0.6125080259511859 0.4181258283983667; 1.0 -1.336609049786048 … -0.18567490803712938 1.0745977099307227], [1.0 -1.0193326822839996 -0.15855601254314888; 1.0 1.7462667837699666 -0.4584376230657152; … ; 1.0 1.4843185594903878 0.42458303115266854; 1.0 0.3791714762820068 0.25150666970865837], [2.155864319e-314, 2.155864319e-314, 2.155864319e-314, 2.247312649e-314, 2.5912441084e-314], [2.6792736896e-314, 2.578915384e-314, 2.6025307574e-314], [2000.0 -16.870943820386742 … -4.678756487678475 -33.013941932083; -16.870943820386742 1972.1480562704003 … 42.18373658967015 -18.84275280240305; … ; -4.678756487678475 42.18373658967015 … 1962.0317062119739 31.94767484234441; -33.013941932083 -18.84275280240305 … 31.94767484234441 1952.6108146037132], [2000.0 -16.870943820386742 … -4.678756487678475 -33.013941932083; 3.207786785008361 51.53509357013415 … -5.599636592147186 -25.64263779027382; 5.886499963119173 -108.8221415845363 … 84.16510226928119 -24.939700580608623], [2000.0 3.207786785008361 5.886499963119173; 3.207786785008361 1988.894096853326 -57.31891154469458; 5.886499963119173 -57.31891154469458 2009.4519396527112], [5.0e-324 0.0 5.0e-324; 5.0e-324 0.0 5.0e-324; 5.0e-324 5.0e-324 0.0], [4209.066417097505, -1849.2613478849603, 1339.123019322386, 396.4337131159357, 1659.0630888170558], [4209.066417097505, -447.626646909811, -2763.9856125358615], 20378.320552515157)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Random.seed!(257)\n",
    "\n",
    "# dimension\n",
    "n, p, q = 2000, 5, 3\n",
    "# predictors\n",
    "X  = [ones(n) randn(n, p - 1)]\n",
    "Z  = [ones(n) randn(n, q - 1)]\n",
    "# parameter values\n",
    "β  = [2.0; -1.0; rand(p - 2)]\n",
    "σ² = 1.5\n",
    "Σ  = fill(0.1, q, q) + 0.9I\n",
    "# generate y\n",
    "y  = X * β + Z * rand(MvNormal(Σ)) + sqrt(σ²) * randn(n)\n",
    "\n",
    "# form an LmmObs object\n",
    "obs = LmmObs(y, X, Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the standard way to evaluate log-density of a multivariate normal, using the Distributions.jl package. Let's evaluate the log-likelihood of this datum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3256.1793358058317"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "μ  = X * β\n",
    "Ω  = Z * Σ * transpose(Z) +  σ² * I\n",
    "mvn = MvNormal(μ, Symmetric(Ω)) # MVN(μ, Σ)\n",
    "logpdf(mvn, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that your answer matches that from Distributions.jl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3256.1793358058335"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L = Matrix(cholesky(Σ).L)\n",
    "logl!(obs, β, L, σ²)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You will lose all 15 + 30 + 30 = 75 points** if the following statement throws `AssertionError`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@assert logl!(obs, β, Matrix(cholesky(Σ).L), σ²) ≈ logpdf(mvn, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks successful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4 Efficiency (30 pts)\n",
    "\n",
    "Benchmarking your code and compare to the Distributions.jl function `logpdf`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: 5546 samples with 1 evaluation.\n",
       " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m … \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m797.583 μs\u001b[22m\u001b[39m … \u001b[35m  7.601 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmin … max\u001b[90m): \u001b[39m0.00% … 86.11%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m848.042 μs               \u001b[22m\u001b[39m\u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ± \u001b[32mσ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m893.888 μs\u001b[22m\u001b[39m ± \u001b[32m155.433 μs\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmean ± σ\u001b[90m):  \u001b[39m0.13% ±  1.16%\n",
       "\n",
       "  \u001b[39m \u001b[39m█\u001b[39m▅\u001b[39m▄\u001b[39m▃\u001b[39m▁\u001b[39m▁\u001b[39m \u001b[39m \u001b[34m \u001b[39m\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[32m \u001b[39m\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \n",
       "  \u001b[39m▅\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m▇\u001b[39m▆\u001b[34m▆\u001b[39m\u001b[39m▅\u001b[39m▄\u001b[39m▃\u001b[39m▃\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[32m▂\u001b[39m\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▃\u001b[39m▄\u001b[39m▆\u001b[39m▅\u001b[39m▄\u001b[39m▃\u001b[39m▃\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▃\u001b[39m▄\u001b[39m▃\u001b[39m▃\u001b[39m▃\u001b[39m▃\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m \u001b[39m▃\n",
       "  798 μs\u001b[90m           Histogram: frequency by time\u001b[39m         1.15 ms \u001b[0m\u001b[1m<\u001b[22m\n",
       "\n",
       " Memory estimate\u001b[90m: \u001b[39m\u001b[33m31.52 KiB\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m3\u001b[39m."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# benchmark the `logpdf` function in Distribution.jl\n",
    "bm1 = @benchmark logpdf($mvn, $y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: 10000 samples with 143 evaluations.\n",
       " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m … \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m718.531 ns\u001b[22m\u001b[39m … \u001b[35m 1.040 μs\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmin … max\u001b[90m): \u001b[39m0.00% … 0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m777.678 ns              \u001b[22m\u001b[39m\u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ± \u001b[32mσ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m777.508 ns\u001b[22m\u001b[39m ± \u001b[32m16.163 ns\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmean ± σ\u001b[90m):  \u001b[39m0.00% ± 0.00%\n",
       "\n",
       "  \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m▁\u001b[39m▂\u001b[39m▅\u001b[39m▃\u001b[39m▆\u001b[39m█\u001b[39m█\u001b[34m█\u001b[39m\u001b[39m▆\u001b[39m▆\u001b[39m▄\u001b[39m▄\u001b[39m▂\u001b[39m▁\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \n",
       "  \u001b[39m▂\u001b[39m▁\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▃\u001b[39m▃\u001b[39m▃\u001b[39m▃\u001b[39m▄\u001b[39m▄\u001b[39m▄\u001b[39m▄\u001b[39m▅\u001b[39m▅\u001b[39m▅\u001b[39m▆\u001b[39m▇\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[34m█\u001b[39m\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m▇\u001b[39m▅\u001b[39m▄\u001b[39m▄\u001b[39m▃\u001b[39m▃\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m \u001b[39m▄\n",
       "  719 ns\u001b[90m          Histogram: frequency by time\u001b[39m          838 ns \u001b[0m\u001b[1m<\u001b[22m\n",
       "\n",
       " Memory estimate\u001b[90m: \u001b[39m\u001b[33m0 bytes\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m0\u001b[39m."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# benchmark your implementation\n",
    "L = Matrix(cholesky(Σ).L)\n",
    "bm2 = @benchmark logl!($obs, $β, $L, $σ²)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The points you will get is\n",
    "$$\n",
    "\\frac{x}{1000} \\times 30,\n",
    "$$\n",
    "where $x$ is the speedup of your program against the standard method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is the points you'll get\n",
    "clamp(median(bm1).time / median(bm2).time / 1000 * 30, 0, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hint**: Apparently I am using 1000 as denominator because I expect your code to be at least $1000 \\times$ faster than the standard method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5 Memory (30 pts)\n",
    "\n",
    "You want to avoid memory allocation in the \"hot\" function `logl!`. You will lose 1 point for each `1 KiB = 1024 bytes` memory allocation. In other words, the points you get for this question is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clamp(30 - median(bm2).memory / 1024, 0, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hint**: I am able to reduce the memory allocation to 0 bytes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q6 Misc (15 pts)\n",
    "\n",
    "Coding style, Git workflow, etc. For reproducibity, make sure we (TA and myself) can run your Jupyter Notebook. That is how we grade Q4 and Q5. If we cannot run it, you will get zero points.\n",
    "\n",
    "**Solution**\n",
    "\n",
    "I have confirmed that the solution is reproducible."
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "jupytext": {
   "formats": "ipynb,qmd"
  },
  "kernelspec": {
   "display_name": "Julia 1.10.0",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.0"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "87px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
